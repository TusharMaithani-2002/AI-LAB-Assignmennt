{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy:\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State {}:\tStay\n",
      "State 8:\tQuit\n",
      "State 9:\tQuit\n",
      "State 10:\tQuit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the MDP\n",
    "prob_correct_answer = [0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "rewards = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]\n",
    "n_states = len(prob_correct_answer)\n",
    "\n",
    "# Set discount factor and convergence threshold\n",
    "gamma = 1\n",
    "epsilon = 0.001\n",
    "\n",
    "# Initialize the value function and policy\n",
    "V = np.zeros(n_states)\n",
    "policy = np.zeros(n_states, dtype=int)\n",
    "\n",
    "while True:\n",
    "    # Initialize the change in value function\n",
    "    delta = 0\n",
    "    \n",
    "    # Perform a single iteration of value iteration for each state\n",
    "    for s in range(n_states):\n",
    "        # Calculate the expected value of each action\n",
    "        stay_value = 0\n",
    "        quit_value = rewards[s]\n",
    "        for s_prime in range(s+1, n_states):\n",
    "            stay_value += prob_correct_answer[s] * (rewards[s] + gamma * V[s_prime])\n",
    "            quit_value += (1 - prob_correct_answer[s]) * rewards[s_prime] * gamma ** (s_prime - s - 1)\n",
    "        \n",
    "        # Determine the optimal value and action for this state\n",
    "        max_value = max(stay_value, quit_value)\n",
    "        if max_value == quit_value:\n",
    "            policy[s] = 1  # 1 represents the \"Quit\" action\n",
    "        else:\n",
    "            policy[s] = 0  # 0 represents the \"Stay\" action\n",
    "        \n",
    "        # Update the value function\n",
    "        delta = max(delta, abs(max_value - V[s]))\n",
    "        V[s] = max_value\n",
    "    \n",
    "    # Check for convergence\n",
    "    if delta < epsilon:\n",
    "        break\n",
    "\n",
    "# Print the optimal policy\n",
    "print(\"Optimal policy:\")\n",
    "for s in range(n_states):\n",
    "    if policy[s] == 1:\n",
    "        print(\"State {}:\\tQuit\".format(s+1))\n",
    "    else:\n",
    "        print(\"State {}:\\tStay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
